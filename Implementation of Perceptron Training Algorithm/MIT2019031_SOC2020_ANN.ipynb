{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement Perceptron training algorithms for AND ,OR, NAND and NOR gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self, input_size, lr=0.1, epochs=100):\n",
    "        self.W = np.around(np.random.uniform(low=-0.5, high=0.5, size=3), 1)\n",
    "        # add one for bias\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "    \n",
    "    def activation_fn(self, x):\n",
    "        return 1 if x >= 0 else 0\n",
    " \n",
    "    def predict(self, x):\n",
    "        z = self.W.T.dot(x)\n",
    "        a = self.activation_fn(z)\n",
    "        return a\n",
    " \n",
    "    def fit(self, X, d):\n",
    "        for _ in range(self.epochs):\n",
    "            for i in range(d.shape[0]):\n",
    "                x = np.insert(X[i], 0, 1)\n",
    "                y = self.predict(x)\n",
    "                e = d[i] - y\n",
    "                self.W = np.around(self.W + self.lr * e * x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(input_size=2)\n",
    "print(perceptron.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AND gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0\tX1\tY\n",
      "0\t0\t0\n",
      "0\t1\t0\n",
      "1\t0\t0\n",
      "1\t1\t1\n",
      "\n",
      "bias = -0.3, w1 = 0.2, w2 = 0.1\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [1, 1]\n",
    "    ])\n",
    "d = np.array([0, 0, 0, 1])\n",
    " \n",
    "perceptron = Perceptron(input_size=2)\n",
    "perceptron.fit(X, d)\n",
    "print(\"X0\\tX1\\tY\")\n",
    "toPrint = [\"{1}\\t{2}\\t{0}\".format(output, *datas) for datas, output in zip(X, d)]\n",
    "for i in toPrint:\n",
    "    print(i)\n",
    "    \n",
    "print(\"\\nbias = {}, w1 = {}, w2 = {}\".format(perceptron.W[0], perceptron.W[1], perceptron.W[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0\tX1\tY\n",
      "0\t0\t0\n",
      "0\t1\t1\n",
      "1\t0\t1\n",
      "1\t1\t1\n",
      "\n",
      "bias = -0.1, w1 = 0.1, w2 = 0.2\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [1, 1]\n",
    "    ])\n",
    "d = np.array([0, 1, 1, 1])\n",
    " \n",
    "perceptron = Perceptron(input_size=2)\n",
    "perceptron.fit(X, d)\n",
    "print(\"X0\\tX1\\tY\")\n",
    "toPrint = [\"{1}\\t{2}\\t{0}\".format(output, *datas) for datas, output in zip(X, d)]\n",
    "for i in toPrint:\n",
    "    print(i)\n",
    "    \n",
    "print(\"\\nbias = {}, w1 = {}, w2 = {}\".format(perceptron.W[0], perceptron.W[1], perceptron.W[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAND gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0\tX1\tY\n",
      "0\t0\t1\n",
      "0\t1\t0\n",
      "1\t0\t0\n",
      "1\t1\t0\n",
      "\n",
      "bias = 0.0, w1 = -0.1, w2 = -0.3\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [1, 1]\n",
    "    ])\n",
    "d = np.array([1, 0, 0, 0])\n",
    " \n",
    "perceptron = Perceptron(input_size=2)\n",
    "perceptron.fit(X, d)\n",
    "print(\"X0\\tX1\\tY\")\n",
    "toPrint = [\"{1}\\t{2}\\t{0}\".format(output, *datas) for datas, output in zip(X, d)]\n",
    "for i in toPrint:\n",
    "    print(i)\n",
    "    \n",
    "print(\"\\nbias = {}, w1 = {}, w2 = {}\".format(perceptron.W[0], perceptron.W[1], perceptron.W[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0\tX1\tY\n",
      "0\t0\t1\n",
      "0\t1\t0\n",
      "1\t0\t0\n",
      "1\t1\t0\n",
      "\n",
      "bias = 0.0, w1 = -0.3, w2 = -0.1\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [1, 1]\n",
    "    ])\n",
    "d = np.array([1, 0, 0, 0])\n",
    " \n",
    "perceptron = Perceptron(input_size=2)\n",
    "perceptron.fit(X, d)\n",
    "print(\"X0\\tX1\\tY\")\n",
    "toPrint = [\"{1}\\t{2}\\t{0}\".format(output, *datas) for datas, output in zip(X, d)]\n",
    "for i in toPrint:\n",
    "    print(i)\n",
    "    \n",
    "print(\"\\nbias = {}, w1 = {}, w2 = {}\".format(perceptron.W[0], perceptron.W[1], perceptron.W[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How you will verify your trained algorithms? Justify your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify this weight vector is correct, let take a example. \n",
    "\n",
    "z = bias + w0 \\* x0 + w1 \\* x1\n",
    "\n",
    "For AND \n",
    "\n",
    "If both inputs are 0, then the pre-activation(z) will be -0.3 + 0 \\* 0.2 + 0 \\* 0.1 = -0.3. When applying our activation function, we get 0, which is exactly 0 AND 0. \n",
    "\n",
    "Similarly we can try this for other gates as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
